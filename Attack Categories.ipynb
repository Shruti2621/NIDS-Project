{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b774306-850a-46c4-8d1a-8c40e8025d17",
   "metadata": {},
   "source": [
    "## Merging 4 csv files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd6d95d5-2669-465d-bec1-cf0846b18dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame shape: (2540047, 49)\n",
      "        srcip  sport          dstip dsport proto state       dur  sbytes  \\\n",
      "0  59.166.0.0   1390  149.171.126.6     53   udp   CON  0.001055     132   \n",
      "1  59.166.0.0  33661  149.171.126.9   1024   udp   CON  0.036133     528   \n",
      "2  59.166.0.6   1464  149.171.126.7     53   udp   CON  0.001119     146   \n",
      "3  59.166.0.5   3593  149.171.126.5     53   udp   CON  0.001209     132   \n",
      "4  59.166.0.3  49664  149.171.126.0     53   udp   CON  0.001169     146   \n",
      "\n",
      "   dbytes  sttl  ...  ct_ftp_cmd  ct_srv_src  ct_srv_dst ct_dst_ltm  \\\n",
      "0     164    31  ...           0           3           7          1   \n",
      "1     304    31  ...           0           2           4          2   \n",
      "2     178    31  ...           0          12           8          1   \n",
      "3     164    31  ...           0           6           9          1   \n",
      "4     178    31  ...           0           7           9          1   \n",
      "\n",
      "   ct_src_ ltm  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  \\\n",
      "0            3                 1                 1               1   \n",
      "1            3                 1                 1               2   \n",
      "2            2                 2                 1               1   \n",
      "3            1                 1                 1               1   \n",
      "4            1                 1                 1               1   \n",
      "\n",
      "   attack_cat  Label  \n",
      "0         NaN      0  \n",
      "1         NaN      0  \n",
      "2         NaN      0  \n",
      "3         NaN      0  \n",
      "4         NaN      0  \n",
      "\n",
      "[5 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Update your path here:\n",
    "data_dir = r\"C:\\Users\\Shruti More\\NIDS Project\"\n",
    "features_path = os.path.join(data_dir, \"NUSW-NB15_features.csv\")\n",
    "\n",
    "# Load column names\n",
    "features_df = pd.read_csv(features_path, encoding='latin1')\n",
    "column_names = features_df['Name'].dropna().tolist()\n",
    "\n",
    "# List of your 4 data CSV files (make sure the file names match exactly)\n",
    "file_list = [\"UNSW-NB15_1.csv\", \"UNSW-NB15_2.csv\", \"UNSW-NB15_3.csv\", \"UNSW-NB15_4.csv\"]\n",
    "\n",
    "all_dfs = []\n",
    "for file in file_list:\n",
    "    file_path = os.path.join(data_dir, file)\n",
    "    df = pd.read_csv(file_path, header=None, names=column_names, low_memory=False)\n",
    "    all_dfs.append(df)\n",
    "\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "print(f\"Combined DataFrame shape: {combined_df.shape}\")\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d8f1f95-ff9a-4fc5-9d42-0c315128dc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique attack categories:\n",
      "[nan 'Exploits' 'Reconnaissance' 'DoS' 'Generic' 'Shellcode' ' Fuzzers'\n",
      " 'Worms' 'Backdoors' 'Analysis' ' Reconnaissance ' 'Backdoor' ' Fuzzers '\n",
      " ' Shellcode ']\n",
      "\n",
      "Attack category distribution:\n",
      "attack_cat\n",
      "Generic             215481\n",
      "Exploits             44525\n",
      " Fuzzers             19195\n",
      "DoS                  16353\n",
      " Reconnaissance      12228\n",
      " Fuzzers              5051\n",
      "Analysis              2677\n",
      "Backdoor              1795\n",
      "Reconnaissance        1759\n",
      " Shellcode            1288\n",
      "Backdoors              534\n",
      "Shellcode              223\n",
      "Worms                  174\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check unique attack categories and their counts\n",
    "print(\"\\nUnique attack categories:\")\n",
    "print(combined_df['attack_cat'].unique())\n",
    "\n",
    "print(\"\\nAttack category distribution:\")\n",
    "print(combined_df['attack_cat'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6232680a-00a3-4592-bb4c-a3a9429849f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned unique attack categories:\n",
      "[nan 'Exploits' 'Reconnaissance' 'DoS' 'Generic' 'Shellcode' 'Fuzzers'\n",
      " 'Worms' 'Backdoor' 'Analysis']\n",
      "\n",
      "Cleaned attack category distribution:\n",
      "attack_cat\n",
      "Generic           215481\n",
      "Exploits           44525\n",
      "Fuzzers            24246\n",
      "DoS                16353\n",
      "Reconnaissance     13987\n",
      "Analysis            2677\n",
      "Backdoor            2329\n",
      "Shellcode           1511\n",
      "Worms                174\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Strip extra spaces and replace inconsistent names\n",
    "combined_df['attack_cat'] = combined_df['attack_cat'].str.strip()\n",
    "\n",
    "# Optional: Standardize similar names (you can customize this)\n",
    "combined_df['attack_cat'] = combined_df['attack_cat'].replace({\n",
    "    'Backdoors': 'Backdoor',\n",
    "    'Shellcode': 'Shellcode',  # ensure proper case\n",
    "    'Fuzzers': 'Fuzzers',\n",
    "    'Reconnaissance': 'Reconnaissance',\n",
    "})\n",
    "\n",
    "# View the cleaned categories\n",
    "print(\"\\nCleaned unique attack categories:\")\n",
    "print(combined_df['attack_cat'].unique())\n",
    "\n",
    "print(\"\\nCleaned attack category distribution:\")\n",
    "print(combined_df['attack_cat'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5348580c-a4cd-49eb-8b68-16d6c96d03b5",
   "metadata": {},
   "source": [
    "## Handling Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe733abe-a431-4f96-8735-41b5eea409d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns with null values:\n",
      "ct_flw_http_mthd    1348145\n",
      "is_ftp_login        1429879\n",
      "attack_cat          2218764\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count of nulls in each column\n",
    "null_counts = combined_df.isnull().sum()\n",
    "\n",
    "# Show only columns with nulls\n",
    "null_counts = null_counts[null_counts > 0]\n",
    "\n",
    "print(\"\\nColumns with null values:\")\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a5158df-d483-45a7-80b4-398939a3d4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.drop(['ct_flw_http_mthd', 'is_ftp_login'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cda88b3-7f36-4590-91e0-f42da6ed7ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srcip                     0\n",
      "sport                     0\n",
      "dstip                     0\n",
      "dsport                    0\n",
      "proto                     0\n",
      "state                     0\n",
      "dur                       0\n",
      "sbytes                    0\n",
      "dbytes                    0\n",
      "sttl                      0\n",
      "dttl                      0\n",
      "sloss                     0\n",
      "dloss                     0\n",
      "service                   0\n",
      "Sload                     0\n",
      "Dload                     0\n",
      "Spkts                     0\n",
      "Dpkts                     0\n",
      "swin                      0\n",
      "dwin                      0\n",
      "stcpb                     0\n",
      "dtcpb                     0\n",
      "smeansz                   0\n",
      "dmeansz                   0\n",
      "trans_depth               0\n",
      "res_bdy_len               0\n",
      "Sjit                      0\n",
      "Djit                      0\n",
      "Stime                     0\n",
      "Ltime                     0\n",
      "Sintpkt                   0\n",
      "Dintpkt                   0\n",
      "tcprtt                    0\n",
      "synack                    0\n",
      "ackdat                    0\n",
      "is_sm_ips_ports           0\n",
      "ct_state_ttl              0\n",
      "ct_ftp_cmd                0\n",
      "ct_srv_src                0\n",
      "ct_srv_dst                0\n",
      "ct_dst_ltm                0\n",
      "ct_src_ ltm               0\n",
      "ct_src_dport_ltm          0\n",
      "ct_dst_sport_ltm          0\n",
      "ct_dst_src_ltm            0\n",
      "attack_cat          2218764\n",
      "Label                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Droped col ct_flw_http_mthd', 'is_ftp_login'\n",
    "print(combined_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba3b90aa-cbcd-43c5-b93a-b091c437cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.drop(['Label'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de8d4277-9937-459b-b37b-91b273f4a7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srcip                     0\n",
      "sport                     0\n",
      "dstip                     0\n",
      "dsport                    0\n",
      "proto                     0\n",
      "state                     0\n",
      "dur                       0\n",
      "sbytes                    0\n",
      "dbytes                    0\n",
      "sttl                      0\n",
      "dttl                      0\n",
      "sloss                     0\n",
      "dloss                     0\n",
      "service                   0\n",
      "Sload                     0\n",
      "Dload                     0\n",
      "Spkts                     0\n",
      "Dpkts                     0\n",
      "swin                      0\n",
      "dwin                      0\n",
      "stcpb                     0\n",
      "dtcpb                     0\n",
      "smeansz                   0\n",
      "dmeansz                   0\n",
      "trans_depth               0\n",
      "res_bdy_len               0\n",
      "Sjit                      0\n",
      "Djit                      0\n",
      "Stime                     0\n",
      "Ltime                     0\n",
      "Sintpkt                   0\n",
      "Dintpkt                   0\n",
      "tcprtt                    0\n",
      "synack                    0\n",
      "ackdat                    0\n",
      "is_sm_ips_ports           0\n",
      "ct_state_ttl              0\n",
      "ct_ftp_cmd                0\n",
      "ct_srv_src                0\n",
      "ct_srv_dst                0\n",
      "ct_dst_ltm                0\n",
      "ct_src_ ltm               0\n",
      "ct_src_dport_ltm          0\n",
      "ct_dst_sport_ltm          0\n",
      "ct_dst_src_ltm            0\n",
      "attack_cat          2218764\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Droped col ct_flw_http_mthd', 'is_ftp_login'\n",
    "print(combined_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e77a1b-3571-4c28-90cd-407a3cb0668e",
   "metadata": {},
   "source": [
    "## Handling Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1570225-ea28-4562-9fce-2b9de4adb2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2218764\n"
     ]
    }
   ],
   "source": [
    "print(combined_df['attack_cat'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5162e512-56e4-4b1e-97d8-edd1c44ed899",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['attack_cat'] = combined_df['attack_cat'].fillna('unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5d5a067-d858-4264-9456-4f58abf48995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(combined_df['attack_cat'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b691db1f-a81e-4db3-9724-fe8b2e432f7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates in NORMAL data: 0\n",
      "Number of duplicates in ATTACK data: 567981\n"
     ]
    }
   ],
   "source": [
    "# Separate the data into normal and attack\n",
    "normal_df = combined_df[combined_df['attack_cat'] == 'Normal']  # or 'normal', depending on the label case\n",
    "attack_df = combined_df[combined_df['attack_cat'] != 'Normal']\n",
    "\n",
    "# Choose a subset of important columns to detect duplicates more meaningfully\n",
    "subset_columns = ['srcip', 'dstip', 'sport', 'dsport', 'proto', 'state', 'sbytes', 'dbytes']\n",
    "\n",
    "# Count duplicates in normal data\n",
    "normal_duplicates = normal_df.duplicated(subset=subset_columns).sum()\n",
    "print(\"Number of duplicates in NORMAL data:\", normal_duplicates)\n",
    "\n",
    "# Count duplicates in attack data\n",
    "attack_duplicates = attack_df.duplicated(subset=subset_columns).sum()\n",
    "print(\"Number of duplicates in ATTACK data:\", attack_duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd008f7d-a2e7-4cfb-a274-bdff8285b2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows based on important features: 148599\n"
     ]
    }
   ],
   "source": [
    "important_cols = ['srcip', 'dstip','dsport','sport','proto', 'service', 'state', 'ct_ftp_cmd', 'attack_cat']\n",
    "duplicates = df.duplicated(subset=important_cols)\n",
    "print(\"Duplicate rows based on important features:\", duplicates.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c378f10b-0aef-4dbd-af52-b4f77d7aa7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proto: 135 unique values\n",
      "state: 16 unique values\n",
      "service: 13 unique values\n",
      "ct_ftp_cmd: 13 unique values\n"
     ]
    }
   ],
   "source": [
    "for col in ['proto', 'state', 'service', 'ct_ftp_cmd']:\n",
    "    print(f\"{col}: {combined_df[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fdda1a7-4a88-4c35-b176-7a17b01d7d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'proto' after reduction: 30\n",
      "proto\n",
      "tcp           1495074\n",
      "udp            990435\n",
      "unas            16202\n",
      "Other           14055\n",
      "arp             10064\n",
      "ospf             7798\n",
      "sctp             1525\n",
      "icmp              524\n",
      "any               411\n",
      "gre               324\n",
      "rsvp              274\n",
      "ipv6              272\n",
      "swipe             262\n",
      "pim               262\n",
      "sun-nd            262\n",
      "mobile            262\n",
      "sep               260\n",
      "ipip              137\n",
      "pri-enc           137\n",
      "etherip           137\n",
      "encap             137\n",
      "aes-sp3-d         137\n",
      "micp              137\n",
      "sprite-rpc        137\n",
      "ax.25             137\n",
      "mtp               137\n",
      "larp              137\n",
      "eigrp             137\n",
      "tcf               137\n",
      "vmtp              137\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Make sure final_df is defined\n",
    "final_df = combined_df.copy()\n",
    "\n",
    "# Step 1: Identify the top 29 protocols\n",
    "top_n = 29\n",
    "top_protocols = final_df['proto'].value_counts().nlargest(top_n).index\n",
    "\n",
    "# Step 2: Replace rare protocols with \"Other\"\n",
    "final_df['proto'] = final_df['proto'].apply(lambda x: x if x in top_protocols else 'Other')\n",
    "\n",
    "# Step 3: Optional - Check the result\n",
    "print(\"Unique values in 'proto' after reduction:\", final_df['proto'].nunique())\n",
    "print(final_df['proto'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "194fef52-b7d8-478c-bbaf-ab5d9c7f3532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2540047, 46)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape before encoding\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d9bd30d-bfe1-4516-8a59-8f20870163d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace less frequent protocols with 'Other'\n",
    "final_df['proto'] = final_df['proto'].apply(lambda x: x if x in top_protocols else 'Other')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a5764da-7c8a-457b-827d-4ed26d71264b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2540047, 46)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape before encoding\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16a683f2-a64b-427e-95b6-8d5238787ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proto\n",
      "tcp           1495074\n",
      "udp            990435\n",
      "unas            16202\n",
      "Other           14055\n",
      "arp             10064\n",
      "ospf             7798\n",
      "sctp             1525\n",
      "icmp              524\n",
      "any               411\n",
      "gre               324\n",
      "rsvp              274\n",
      "ipv6              272\n",
      "swipe             262\n",
      "pim               262\n",
      "sun-nd            262\n",
      "mobile            262\n",
      "sep               260\n",
      "ipip              137\n",
      "pri-enc           137\n",
      "etherip           137\n",
      "encap             137\n",
      "aes-sp3-d         137\n",
      "micp              137\n",
      "sprite-rpc        137\n",
      "ax.25             137\n",
      "mtp               137\n",
      "larp              137\n",
      "eigrp             137\n",
      "tcf               137\n",
      "vmtp              137\n",
      "Name: count, dtype: int64\n",
      "Unique protocols after grouping: 30\n"
     ]
    }
   ],
   "source": [
    "print(final_df['proto'].value_counts())\n",
    "print(\"Unique protocols after grouping:\", final_df['proto'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36686e88-5eae-413b-af22-116d4bbfa5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['proto', 'state', 'service', 'ct_ftp_cmd']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c916edca-b547-44ad-8fd1-e67aab1ce3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ New shape after encoding: (2540047, 110)\n",
      "        srcip  sport          dstip dsport       dur  sbytes  dbytes  sttl  \\\n",
      "0  59.166.0.0   1390  149.171.126.6     53  0.001055     132     164    31   \n",
      "1  59.166.0.0  33661  149.171.126.9   1024  0.036133     528     304    31   \n",
      "2  59.166.0.6   1464  149.171.126.7     53  0.001119     146     178    31   \n",
      "3  59.166.0.5   3593  149.171.126.5     53  0.001209     132     164    31   \n",
      "4  59.166.0.3  49664  149.171.126.0     53  0.001169     146     178    31   \n",
      "\n",
      "   dttl  sloss  ...  ct_ftp_cmd_3  ct_ftp_cmd_4  ct_ftp_cmd_5  ct_ftp_cmd_6  \\\n",
      "0    29      0  ...         False         False         False         False   \n",
      "1    29      0  ...         False         False         False         False   \n",
      "2    29      0  ...         False         False         False         False   \n",
      "3    29      0  ...         False         False         False         False   \n",
      "4    29      0  ...         False         False         False         False   \n",
      "\n",
      "   ct_ftp_cmd_8  ct_ftp_cmd_   ct_ftp_cmd_0  ct_ftp_cmd_1  ct_ftp_cmd_2  \\\n",
      "0         False         False         False         False         False   \n",
      "1         False         False         False         False         False   \n",
      "2         False         False         False         False         False   \n",
      "3         False         False         False         False         False   \n",
      "4         False         False         False         False         False   \n",
      "\n",
      "   ct_ftp_cmd_4  \n",
      "0         False  \n",
      "1         False  \n",
      "2         False  \n",
      "3         False  \n",
      "4         False  \n",
      "\n",
      "[5 rows x 110 columns]\n"
     ]
    }
   ],
   "source": [
    "# Apply One-Hot Encoding\n",
    "final_df = pd.get_dummies(final_df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Show the new shape and sample\n",
    "print(\"✅ New shape after encoding:\", final_df.shape)\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26316d6f-b429-460c-8396-6a7e4ba13b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Converted all boolean columns to 0 and 1.\n",
      "        srcip  sport          dstip dsport       dur  sbytes  dbytes  sttl  \\\n",
      "0  59.166.0.0   1390  149.171.126.6     53  0.001055     132     164    31   \n",
      "1  59.166.0.0  33661  149.171.126.9   1024  0.036133     528     304    31   \n",
      "2  59.166.0.6   1464  149.171.126.7     53  0.001119     146     178    31   \n",
      "3  59.166.0.5   3593  149.171.126.5     53  0.001209     132     164    31   \n",
      "4  59.166.0.3  49664  149.171.126.0     53  0.001169     146     178    31   \n",
      "\n",
      "   dttl  sloss  ...  ct_ftp_cmd_3  ct_ftp_cmd_4  ct_ftp_cmd_5  ct_ftp_cmd_6  \\\n",
      "0    29      0  ...             0             0             0             0   \n",
      "1    29      0  ...             0             0             0             0   \n",
      "2    29      0  ...             0             0             0             0   \n",
      "3    29      0  ...             0             0             0             0   \n",
      "4    29      0  ...             0             0             0             0   \n",
      "\n",
      "   ct_ftp_cmd_8  ct_ftp_cmd_   ct_ftp_cmd_0  ct_ftp_cmd_1  ct_ftp_cmd_2  \\\n",
      "0             0             0             0             0             0   \n",
      "1             0             0             0             0             0   \n",
      "2             0             0             0             0             0   \n",
      "3             0             0             0             0             0   \n",
      "4             0             0             0             0             0   \n",
      "\n",
      "   ct_ftp_cmd_4  \n",
      "0             0  \n",
      "1             0  \n",
      "2             0  \n",
      "3             0  \n",
      "4             0  \n",
      "\n",
      "[5 rows x 110 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert True/False to 1/0 for the entire DataFrame\n",
    "final_df = final_df.astype({col: int for col in final_df.select_dtypes(include='bool').columns})\n",
    "\n",
    "# Check result\n",
    "print(\"✅ Converted all boolean columns to 0 and 1.\")\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465b832f-b574-4cff-94fd-ae2e181c0e5e",
   "metadata": {},
   "source": [
    "## Selecting top 50 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50c0b448-3b62-4f34-ba79-63e954d07cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values:\n",
      "Series([], dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "# Show only columns that have at least 1 NaN\n",
    "null_columns = final_df.columns[final_df.isnull().any()]\n",
    "print(\"Columns with missing values:\")\n",
    "print(final_df[null_columns].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7a6605d-e35f-4523-aa43-64c63938c6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['attack_cat'] = final_df['attack_cat'].fillna('unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1af0a9ff-ed75-4ce7-abab-3cd696e15440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(final_df['attack_cat'].isnull().sum())  # should print 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1406f4f8-e1db-43fa-9744-1b0575a9e0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 selected features:\n",
      " Index(['sbytes', 'dbytes', 'sttl', 'dttl', 'sloss', 'dloss', 'Sload', 'Dload',\n",
      "       'Spkts', 'Dpkts', 'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz',\n",
      "       'dmeansz', 'trans_depth', 'Sjit', 'Djit', 'Stime', 'Ltime', 'tcprtt',\n",
      "       'synack', 'ackdat', 'ct_state_ttl', 'ct_srv_src', 'ct_srv_dst',\n",
      "       'ct_dst_ltm', 'ct_src_ ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm',\n",
      "       'ct_dst_src_ltm', 'proto_any', 'proto_gre', 'proto_ospf', 'proto_sctp',\n",
      "       'proto_tcp', 'proto_udp', 'proto_unas', 'state_CON', 'state_FIN',\n",
      "       'state_INT', 'service_dns', 'service_ftp-data', 'service_http',\n",
      "       'service_pop3', 'service_smtp', 'service_snmp', 'ct_ftp_cmd_ ',\n",
      "       'ct_ftp_cmd_0'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Drop non-numeric or identifier columns (IPs and ports)\n",
    "cols_to_drop = ['srcip', 'dstip', 'sport', 'dsport']\n",
    "X = final_df.drop(columns=cols_to_drop + ['attack_cat'])  # 'attack_cat' is the target\n",
    "y = final_df['attack_cat']\n",
    "\n",
    "# Apply SelectKBest to select top 50 features\n",
    "selector = SelectKBest(score_func=f_classif, k=50)\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Get the names of selected features\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(\"Top 50 selected features:\\n\", selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a827da09-f11c-4e0f-8f7c-3b6ee44e590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only selected features\n",
    "X = X[selected_features]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39f422fe-6fc4-46a3-bff7-2987f05fc797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2032037, 50)\n",
      "X_test shape: (508010, 50)\n",
      "y_train shape: (2032037,)\n",
      "y_test shape: (508010,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a421eb2-966e-445e-8538-0ca1db74dfea",
   "metadata": {},
   "source": [
    "## Modelling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93b92ac-6550-45bb-a094-21c0770522a3",
   "metadata": {},
   "source": [
    "### Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "624934bb-7d0f-471c-9043-fbc25b913677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Accuracy: 0.9822936556367\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.69      0.08      0.14       550\n",
      "      Backdoor       0.83      0.08      0.15       477\n",
      "           DoS       0.33      0.26      0.29      3315\n",
      "      Exploits       0.62      0.81      0.70      8732\n",
      "       Fuzzers       0.73      0.64      0.68      4784\n",
      "       Generic       1.00      0.99      0.99     43110\n",
      "Reconnaissance       0.93      0.78      0.85      2850\n",
      "     Shellcode       0.66      0.65      0.65       320\n",
      "         Worms       0.57      0.10      0.17        41\n",
      "       unknown       1.00      1.00      1.00    443831\n",
      "\n",
      "      accuracy                           0.98    508010\n",
      "     macro avg       0.74      0.54      0.56    508010\n",
      "  weighted avg       0.98      0.98      0.98    508010\n",
      "\n",
      "🛠️ Training time: 613.44 seconds\n",
      "📤 Prediction time: 11.42 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "\n",
    "# Example: Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 1. Initialize model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 2. Train\n",
    "start_train = time.time()\n",
    "rf.fit(X_train, y_train)\n",
    "end_train = time.time()\n",
    "\n",
    "# 3. Predict\n",
    "start_pred = time.time()\n",
    "y_pred = rf.predict(X_test)\n",
    "end_pred = time.time()\n",
    "\n",
    "# 4. Evaluate\n",
    "print(\"🎯 Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"🛠️ Training time: {end_train - start_train:.2f} seconds\")\n",
    "print(f\"📤 Prediction time: {end_pred - start_pred:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e95c8d2-8471-4d8b-9fce-6b41ff66e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b448bcd-02d7-4dd1-83ae-b0cdc7405725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Reuse X and y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_pipeline, numeric_cols)\n",
    "])\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# ✅ THIS IS REQUIRED\n",
    "pipeline_rf.fit(X_train, y_train)\n",
    "\n",
    "# ✅ Now save the trained pipeline\n",
    "joblib.dump(pipeline_rf, 'pipeline_rf.pkl')\n",
    "print(\"✅ Saved: pipeline_rf.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84b3413f-d0c5-4417-b5e3-189925bffe43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved test file: test_sample_5rows.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sloss</th>\n",
       "      <th>dloss</th>\n",
       "      <th>Sload</th>\n",
       "      <th>Dload</th>\n",
       "      <th>Spkts</th>\n",
       "      <th>Dpkts</th>\n",
       "      <th>...</th>\n",
       "      <th>state_FIN</th>\n",
       "      <th>state_INT</th>\n",
       "      <th>service_dns</th>\n",
       "      <th>service_ftp-data</th>\n",
       "      <th>service_http</th>\n",
       "      <th>service_pop3</th>\n",
       "      <th>service_smtp</th>\n",
       "      <th>service_snmp</th>\n",
       "      <th>ct_ftp_cmd_</th>\n",
       "      <th>ct_ftp_cmd_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132</td>\n",
       "      <td>164</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500473.93750</td>\n",
       "      <td>621800.93750</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>528</td>\n",
       "      <td>304</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87676.08594</td>\n",
       "      <td>50480.17188</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>521894.53130</td>\n",
       "      <td>636282.37500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>164</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>436724.56250</td>\n",
       "      <td>542597.18750</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>499572.25000</td>\n",
       "      <td>609067.56250</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sbytes  dbytes  sttl  dttl  sloss  dloss         Sload         Dload  \\\n",
       "0     132     164    31    29      0      0  500473.93750  621800.93750   \n",
       "1     528     304    31    29      0      0   87676.08594   50480.17188   \n",
       "2     146     178    31    29      0      0  521894.53130  636282.37500   \n",
       "3     132     164    31    29      0      0  436724.56250  542597.18750   \n",
       "4     146     178    31    29      0      0  499572.25000  609067.56250   \n",
       "\n",
       "   Spkts  Dpkts  ...  state_FIN  state_INT  service_dns  service_ftp-data  \\\n",
       "0      2      2  ...          0          0            1                 0   \n",
       "1      4      4  ...          0          0            0                 0   \n",
       "2      2      2  ...          0          0            1                 0   \n",
       "3      2      2  ...          0          0            1                 0   \n",
       "4      2      2  ...          0          0            1                 0   \n",
       "\n",
       "   service_http  service_pop3  service_smtp  service_snmp  ct_ftp_cmd_   \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   ct_ftp_cmd_0  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---- create a 5-row sample CSV for manual testing ----\n",
    "import pandas as pd\n",
    "\n",
    "# X is the feature matrix you used for training *after* SelectKBest\n",
    "X = final_df[selected_features]        # make sure selected_features is your top-50 list\n",
    "\n",
    "sample_df = X.head(5)                  # take first 5 rows (or .sample(5, random_state=42))\n",
    "sample_path = \"test_sample_5rows.csv\"  # will be saved in current folder\n",
    "sample_df.to_csv(sample_path, index=False)\n",
    "\n",
    "print(f\"✅ Saved test file: {sample_path}\")\n",
    "display(sample_df)                     # optional: show what you saved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "343be4e7-b4cc-4fb3-9332-b82cb2eaa0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: manual_test_sample.csv\n"
     ]
    }
   ],
   "source": [
    "# Assuming your processed DataFrame is called 'final_df'\n",
    "sample_df = final_df.head(5)\n",
    "\n",
    "# Save to CSV without index column\n",
    "sample_df.to_csv(\"manual_test_sample.csv\", index=False)\n",
    "\n",
    "print(\"✅ Saved: manual_test_sample.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8b6dd78-76fb-44e6-ac04-8d6f3ee7788d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  srcip  sport          dstip dsport proto state       dur  \\\n",
      "53230        59.166.0.5   6807  149.171.126.6     21   tcp   FIN  0.883703   \n",
      "1823779      59.166.0.8   3083  149.171.126.8   1106   tcp   FIN  0.331832   \n",
      "2479738  149.171.126.10   1043   175.45.176.0     53   udp   INT  0.000007   \n",
      "923745       59.166.0.5  13382  149.171.126.2     53   udp   CON  0.001122   \n",
      "1700724      59.166.0.7  34971  149.171.126.1     80   tcp   FIN  1.122783   \n",
      "\n",
      "         sbytes  dbytes  sttl  ...  ct_state_ttl  ct_ftp_cmd  ct_srv_src  \\\n",
      "53230      2934    3742    31  ...             0           1           1   \n",
      "1823779    5486   94690    31  ...             0                       5   \n",
      "2479738     264       0    60  ...             0                      31   \n",
      "923745      130     162    31  ...             0           0           1   \n",
      "1700724    1580   10168    31  ...             0                       1   \n",
      "\n",
      "        ct_srv_dst  ct_dst_ltm  ct_src_ ltm  ct_src_dport_ltm  \\\n",
      "53230            1           6            3                 1   \n",
      "1823779          1           3            3                 1   \n",
      "2479738         31          31           31                31   \n",
      "923745           3           2            2                 1   \n",
      "1700724          2           9            4                 1   \n",
      "\n",
      "         ct_dst_sport_ltm  ct_dst_src_ltm  attack_cat  \n",
      "53230                   1               3     unknown  \n",
      "1823779                 1               1     unknown  \n",
      "2479738                15              31     unknown  \n",
      "923745                  1               1     unknown  \n",
      "1700724                 1               1     unknown  \n",
      "\n",
      "[5 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "random_sample = combined_df.sample(n=5, random_state=42)\n",
    "print(random_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "642d674e-dd70-4e3e-ad23-398658083ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  srcip  sport          dstip dsport proto state       dur  \\\n",
      "53230        59.166.0.5   6807  149.171.126.6     21   tcp   FIN  0.883703   \n",
      "1823779      59.166.0.8   3083  149.171.126.8   1106   tcp   FIN  0.331832   \n",
      "2479738  149.171.126.10   1043   175.45.176.0     53   udp   INT  0.000007   \n",
      "923745       59.166.0.5  13382  149.171.126.2     53   udp   CON  0.001122   \n",
      "1700724      59.166.0.7  34971  149.171.126.1     80   tcp   FIN  1.122783   \n",
      "\n",
      "         sbytes  dbytes  sttl  ...  ct_state_ttl  ct_ftp_cmd  ct_srv_src  \\\n",
      "53230      2934    3742    31  ...             0           1           1   \n",
      "1823779    5486   94690    31  ...             0                       5   \n",
      "2479738     264       0    60  ...             0                      31   \n",
      "923745      130     162    31  ...             0           0           1   \n",
      "1700724    1580   10168    31  ...             0                       1   \n",
      "\n",
      "        ct_srv_dst  ct_dst_ltm  ct_src_ ltm  ct_src_dport_ltm  \\\n",
      "53230            1           6            3                 1   \n",
      "1823779          1           3            3                 1   \n",
      "2479738         31          31           31                31   \n",
      "923745           3           2            2                 1   \n",
      "1700724          2           9            4                 1   \n",
      "\n",
      "         ct_dst_sport_ltm  ct_dst_src_ltm  attack_cat  \n",
      "53230                   1               3     unknown  \n",
      "1823779                 1               1     unknown  \n",
      "2479738                15              31     unknown  \n",
      "923745                  1               1     unknown  \n",
      "1700724                 1               1     unknown  \n",
      "\n",
      "[5 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "random_sample = combined_df.sample(n=5, random_state=42)\n",
    "print(random_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94c1ca79-07d2-457b-b84b-b3d4db1d0c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample.to_csv(\"sample_5_rows.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2ed1dd0-897b-47e9-a597-61cb69945bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 5 random attack rows to: C:\\Users\\Shruti More\\NIDS Project\\attack_only_5_sample.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the already saved combined dataset\n",
    "combined_path = r\"C:\\Users\\Shruti More\\NIDS Project\\UNSW_combined.csv\"\n",
    "combined_df = pd.read_csv(combined_path, low_memory=False)\n",
    "\n",
    "# Filter attack rows only (non-normal)\n",
    "attack_rows = combined_df[combined_df['attack_cat'].astype(str).str.lower().str.strip() != 'normal']\n",
    "\n",
    "# Take 5 random attack rows\n",
    "sampled_attacks = attack_rows.sample(n=5, random_state=42)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = r\"C:\\Users\\Shruti More\\NIDS Project\\attack_only_5_sample.csv\"\n",
    "sampled_attacks.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Saved 5 random attack rows to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b918ed17-6630-4a28-bb40-1ed1e0a7c967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved DoS & Exploits sample to: C:\\Users\\Shruti More\\NIDS Project\\dos_exploits_sample.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the combined dataset\n",
    "combined_path = r\"C:\\Users\\Shruti More\\NIDS Project\\UNSW_combined.csv\"\n",
    "df = pd.read_csv(combined_path, low_memory=False)\n",
    "\n",
    "# Clean and standardize the 'attack_cat' column\n",
    "df['attack_cat'] = df['attack_cat'].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Filter for only 'dos' and 'exploits'\n",
    "filtered_df = df[df['attack_cat'].isin(['dos', 'exploits'])]\n",
    "\n",
    "# Take a random sample (change n=10 if you want more or fewer)\n",
    "sampled_df = filtered_df.sample(n=10, random_state=42)\n",
    "\n",
    "# Save the result\n",
    "output_path = r\"C:\\Users\\Shruti More\\NIDS Project\\dos_exploits_sample.csv\"\n",
    "sampled_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Saved DoS & Exploits sample to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7c17b2-a028-4687-a289-2c27daa63c15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
